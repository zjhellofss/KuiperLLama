# è‡ªåˆ¶å¤§æ¨¡å‹æ¨ç†æ¡†æ¶
> å¸¦ä½ ä»é›¶å†™ä¸€ä¸ªæ”¯æŒLLamaæ¨ç†ï¼Œæ”¯æŒCudaåŠ é€Ÿçš„å¤§æ¨¡å‹æ¡†æ¶

**ğŸ™‹ğŸ™‹ğŸ™‹ è‡ªåˆ¶å¤§æ¨¡å‹æ¨ç†æ¡†æ¶ç«çƒ­è¿›è¡Œä¸­ï¼Œåªè¦178å—ï¼Œè¯·åŠ ä¸‹æ–¹å¾®ä¿¡äº†è§£**

<img src="./imgs/me.jpg" alt="me" height="480px" width="400px" />

## é¡¹ç›®è¿è¡Œæ•ˆæœ
> LLama1.1b fp32æ¨¡å‹ï¼Œè§†é¢‘æ— åŠ é€Ÿï¼Œè¿è¡Œå¹³å°ä¸ºNvidia 3060 laptop

![](./imgs/do.gif)

## è¯¾ç¨‹ç›®å½•
åªè¦178å—ï¼Œåªè¦178å—ï¼Œåªè¦178å—ï¼é‡è¦çš„äº‹æƒ…è¯´ä¸‰éï¼ï¼ï¼

**ä¸€ã€é¡¹ç›®æ•´ä½“æ¶æ„å’Œè®¾è®¡**
> å­¦ä¹ æ¶æ„æ€ç»´ï¼Œé˜²æ­¢è‡ªå·±åªä¼šä¼˜åŒ–å±€éƒ¨å®ç°

1. ç¯å¢ƒçš„å®‰è£…å’Œè¯¾ç¨‹ç®€ä»‹
2. èµ„æºç®¡ç†å’Œå†…å­˜ç®¡ç†ç±»çš„è®¾è®¡ä¸å®ç°
3. å¼ é‡ç±»çš„è®¾è®¡ä¸å®ç°
4. ç®—å­ç±»çš„è®¾è®¡ä¸å®ç°
5. ç®—å­çš„æ³¨å†Œå’Œç®¡ç†

**äºŒã€è¡¥é½ç®—æ³•å·¥ç¨‹å¸ˆæ€ç»´**
> åœ¨ç®—æ³•å±‚é¢è®²è§£å¤§æ¨¡å‹å’ŒTransformerçš„åŸç†ä¹‹åï¼Œå¼€å§‹å¯¹LLama2è¿›è¡Œæ”¯æŒ

6. LLamaæ¨¡å‹çš„åˆ†æ
7. MMapå†…å­˜æ˜ å°„æŠ€æœ¯æ‰“å¼€å¤§æ¨¡å‹çš„æƒé‡æ–‡ä»¶
8. LLamaæ¨¡å‹æ–‡ä»¶çš„å‚æ•°å’Œæƒé‡è½½å…¥ 
9. LLamaä¸­å„ä¸ªå±‚çš„åˆå§‹åŒ–ä»¥åŠè¾“å…¥å¼ é‡ã€æƒé‡å¼ é‡çš„åˆ†é…å’Œç”³è¯·
10. å®ç°å¤§æ¨¡å‹ä¸­çš„KV Cacheæœºåˆ¶

**ä¸‰ã€æ¨¡å‹çš„é‡åŒ–**
> ä¸ºäº†å‡å°‘æ˜¾å­˜çš„å ç”¨ï¼Œæˆ‘ä»¬å¼€å‘äº†int8æ¨¡å‹é‡åŒ–æ¨¡å—
11. é‡åŒ–æ¨¡å‹æƒé‡çš„å¯¼å‡º
12. é‡åŒ–ç³»æ•°å’Œæƒé‡çš„åŠ è½½
13. é‡åŒ–ä¹˜æ³•ç®—å­çš„å®ç°

**å››ã€CudaåŸºç¡€å’Œç®—å­å®ç°**
> å¸¦ä½ å­¦Cudaå¹¶åœ¨å®æˆ˜å¤§æ¨¡å‹ç®—å­çš„å®ç°ï¼Œä¸ºå¤§æ¨¡å‹æ¨ç†èµ‹èƒ½
14. CudaåŸºç¡€å…¥é—¨1 - å†…å®¹å¾…å®š
15. CudaåŸºç¡€å…¥é—¨2 - å†…å®¹å¾…å®š
16. CudaåŸºç¡€å…¥é—¨3 - å†…å®¹å¾…å®š
17. CudaåŸºç¡€å…¥é—¨4 - å†…å®¹å¾…å®š
18. RMSNormç®—å­çš„Cudaå®ç°
19. Softmaxç®—å­çš„Cudaå®ç° 
20. Addç®—å­çš„Cudaå®ç° 
21. Swigluç®—å­çš„Cudaå®ç° 
22. GEMVç®—å­çš„Cudaå®ç° 
23. å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„Cudaå®ç° 
24. è®©æ¡†æ¶å¢åŠ Cudaè®¾å¤‡çš„æ”¯æŒå’Œç®¡ç† 
25. å®ŒæˆCudaæ¨ç†æµç¨‹

**äº”ã€ç”¨æ¨ç†æ¡†æ¶åšç‚¹æœ‰è¶£çš„äº‹æƒ…**

26. æ–‡æœ¬ç”Ÿæˆ
27. è®²ä¸€æ®µå°æ•…äº‹
28. è®©å¤§æ¨¡å‹å’Œä½ è¿›è¡Œå¤šè½®å¯¹è¯


**å…­ã€å­¦ä¹ å…¶ä»–å•†ç”¨æ¨ç†æ¡†æ¶çš„å®ç°ï¼ŒæŸ¥æ¼è¡¥ç¼º**

29. LLama.cppçš„è®¾è®¡å’Œå®ç°è®²è§£

    *è¿™é‡Œæœ‰å¤šä¸ªå°èŠ‚*
30. Miopenï¼ˆAMDå‡ºå“ï¼Œå¯¹æ ‡CUDNNï¼‰çš„è®¾è®¡å’Œå®ç°è®²è§£

    *è¿™é‡Œæœ‰å¤šä¸ªå°èŠ‚*
32. æ€»ç»“


## ç¬¬ä¸‰æ–¹ä¾èµ–
1. google glog https://github.com/google/glog
2. google gtest https://github.com/google/googletest
3. sentencepiece https://github.com/google/sentencepiece
4. armadillo + openblas https://arma.sourceforge.net/download.html
5. Cuda Toolkit

**openblasä½œä¸ºarmadilloçš„åç«¯æ•°å­¦åº“ï¼ŒåŠ é€ŸçŸ©é˜µä¹˜æ³•ç­‰æ“ä½œï¼Œä¹Ÿå¯ä»¥é€‰ç”¨Intel-MKLï¼Œè¿™ä¸ªåº“ç”¨äºCPUä¸Šçš„æ¨ç†è®¡ç®—**


## æ¨¡å‹ä¸‹è½½åœ°å€
1. llama2 https://pan.baidu.com/s/1PF5KqvIvNFR8yDIY1HmTYA?pwd=ma8r æˆ– https://huggingface.co/fushenshen/lession_model/tree/main

2. Tiny LLama 
* tinyllamaæ¨¡å‹ https://huggingface.co/karpathy/tinyllamas/tree/main
* tinyllamaåˆ†è¯å™¨ https://huggingface.co/yahma/llama-7b-hf/blob/main/tokenizer.model

## æ¨¡å‹å¯¼å‡º
```shell
python export.py llama2_7b.bin --meta-llama path/to/llama/model/7B
# ä½¿ç”¨--hfæ ‡ç­¾ä»hugging faceä¸­åŠ è½½æ¨¡å‹ï¼Œ æŒ‡å®š--version3å¯ä»¥å¯¼å‡ºé‡åŒ–æ¨¡å‹
# å…¶ä»–ä½¿ç”¨æ–¹æ³•è¯·çœ‹export.pyä¸­çš„å‘½ä»¤è¡Œå‚æ•°å®ä¾‹
```


## ç¼–è¯‘æ–¹æ³•
```shell
  # å‡è®¾å·²ç»è£…å¥½ä¸Šè¿°çš„ç¬¬ä¸‰æ–¹ä¾èµ–
  mkdir build 
  cd build
  cmake ..
  make -j16
```

## ç”Ÿæˆæ–‡æœ¬çš„æ–¹æ³•
```shell
./llama_infer llama2_7b.bin tokenizer.model

```
